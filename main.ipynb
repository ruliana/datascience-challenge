{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Challenge\n",
    "\n",
    "(refer to README for the challenge description)\n",
    "\n",
    "My first approach was to stick to the basics: TF-IDF + Naive Bayes. The results were no good, so I tried several flavors of SVM.\n",
    "\n",
    "Why?\n",
    "\n",
    "Naive Bayes is simple, fast and had some great results in the past for text classification. I try it first to have a baseline.\n",
    "\n",
    "SVM seems to be one of the best in the present days, unless we go to Neural Networks, I guess, so it was my next step. The classification accuracy increased a lot.\n",
    "\n",
    "I didn't reach accuracy over 90% as the pre-requisites, probably my data preparation is poor. I tried stemming, but the results didn't improved much. Maybe Latent Semantic Analysis to identify synonyms, but it seem too much right now.\n",
    "\n",
    "As you asked for >90% accuracy in 2-4 hours, my feeling is that I'm missing something really obvious here. But...\n",
    "\n",
    "Anyway... my next steps would be:\n",
    "\n",
    "1. Talk to someone more experienced on that (in a real situation, of course).\n",
    "2. Search a little more for another algorithm.\n",
    "3. Experimenting with feature engineering, the algorithms don't make miracles, but playing with the features usually leads to big improvements. That's were I'm probably missing something, like separate Pros and Cons.\n",
    "4. Spend a little more time doing Grid Search. It's slow, but requires only computer time, and also it can improve a lot some models.\n",
    "5. Precision and Recall. I wouldn't finish this without calculate them. IMHO, they provide a good picture of the model performance. Accuracy can be misleading,\n",
    "\n",
    "Also, I would create separate models for each language. The stemming in languages that have more verb flexion (latin languages mostly) can make a bigger difference.\n",
    "\n",
    "Finally, I made a big mistake here, I tried to use the whole data set for all algorithms. It's fast for the MultinomialNB and SGDClassifier, but it was really slow with the other algorithms I tried (SVC, NuSVC, XGBoost). That made me spend a lot of time just waiting instead of play more with the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing\n",
    "\n",
    "Fist run:\n",
    "\n",
    "    pipenv install\n",
    "    pipenv shell\n",
    "    python -m ipykernel install --user --name=<env-name>\n",
    "    jupyter notebook\n",
    "\n",
    "Once the kernel is installed:\n",
    "\n",
    "   pipenv run jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ronie/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and check the format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labelmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pros - The people who work here are brilliant ...</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pros Start-up vibes Fast growing company Tech-...</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pros The team is great, I love the ambition of...</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pros The company is constantly growing, and at...</td>\n",
       "      <td>adaptability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pros Cool office. Friendly people. Good atmosp...</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       labelmax\n",
       "0  Pros - The people who work here are brilliant ...       customer\n",
       "1  Pros Start-up vibes Fast growing company Tech-...       customer\n",
       "2  Pros The team is great, I love the ambition of...  collaboration\n",
       "3  Pros The company is constantly growing, and at...   adaptability\n",
       "4  Pros Cool office. Friendly people. Good atmosp...  collaboration"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_pickle('data/labelled_dataset.pickle')\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Pros - The people who work here are brilliant (intelligent, hard-working etc.) - Exciting career opportunities, plenty of room to grow! - Great company culture, social events etc. - Management really value everyone's opinion and are open to ideas - Ambitious company, always working to grow and improve - I feel like my work is really valued, and outstanding performance is always recognised by management Cons - Salary isn't great compared to other grad jobs, hopefully this will improve as the company grows - Occasionally have to work weekends, would much rather there was a separate weekend team - Communication could be better about changes in the company, future plans etc. Advice to Management - Keep listening to your employees - Don't become cold and corporate. Airsorted needs to keep the company spirit, even when it is a big global company.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer         26981\n",
       "collaboration    21067\n",
       "result           18948\n",
       "adaptability     17204\n",
       "detail            4030\n",
       "integrity         2815\n",
       "null               535\n",
       "Name: labelmax, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.labelmax.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = raw[raw.labelmax != 'null'] # No classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I tried to use stemming early on, no good results. Little improvement and it slowed the process down a lot!\n",
    "\n",
    "#from nltk.stem.snowball import EnglishStemmer\n",
    "\n",
    "# stemmer = EnglishStemmer()\n",
    "# analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "# def stemmed_words(doc):\n",
    "#     return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "# word_counter = CountVectorizer(stop_words='english',\n",
    "#                                analyzer=stemmed_words,\n",
    "#                                max_df=0.95, # Remove domain specific words like \"Pros\" and \"Cons\"\n",
    "#                                min_df=2)  # Remove words seen only once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers\n",
    "\n",
    "This little functions help to test with different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_with(classifier):\n",
    "    \"Base pipeline for text classification using bag of words\"\n",
    "    word_counter = CountVectorizer(stop_words='english',\n",
    "                                   max_df=0.95, # Remove domain specific words like \"Pros\" and \"Cons\"\n",
    "                                   min_df=2)  # Remove words seen only once\n",
    "\n",
    "    return Pipeline([('frequency', word_counter),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('model', classifier)])\n",
    "\n",
    "def fast_accuracy_for(model, features, target):\n",
    "    \"Simple train test split, so we spend less time testing\"\n",
    "    features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2)\n",
    "    pipeline = pipeline_with(model)\n",
    "    pipeline.fit(features_train, target_train)\n",
    "    target_predicted = pipeline.predict(features_test)\n",
    "    return accuracy_score(target_test, target_predicted)\n",
    "    \n",
    "\n",
    "def accuracy_for(model, features, target):\n",
    "    \"Use cross validation for more reliable results, replace 'fast_accuracy_for' with this after some tests.\"\n",
    "    accuracy = cross_val_score(pipeline_with(model), features, target, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "    return accuracy.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Naive Bayes is my first try to classify texts. Sometimes it is good enough and it's fast, I use it as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4991591807521781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "print(accuracy_for(MultinomialNB(), clean.text, clean.labelmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "SVM does a great job with text classification. As expected, the performance here makes a great jump from Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7368770066607537\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "print(accuracy_for(SGDClassifier(max_iter=5), clean.text, clean.labelmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7671477575325867\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "print(accuracy_for(LinearSVC(), clean.text, clean.labelmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "Never used it before, but it's a winner in Kaggle competitions, so let's try it for text classification.\n",
    "\n",
    "Results:\n",
    "\n",
    "- It's way slower than the others.\n",
    "- No good results in the first run (acc ~0.5). I probably need to prepare the data better for text classification.\n",
    "- I got some warnings from scipy, but it seems expected.\n",
    "\n",
    "It was a very naive approach, but fairly cheap to try (but I spent 30 min waiting for a response, bad move)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from xgboost import XGBClassifier\n",
    "#print(fast_accuracy_for(XGBClassifier()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve best options\n",
    "\n",
    "Naive Bayes and SVM are great. Let's try to improve their parameters (took a long time). Here I experiment just for one algorithm, but I would try with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'frequency__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "              'frequency__max_df': [0.5, 0.7, 0.9],\n",
    "              'frequency__min_df': [1, 2],\n",
    "              'tfidf__sublinear_tf': [True, False]}\n",
    "\n",
    "model = pipeline_with(LinearSVC()) \n",
    "grid = GridSearchCV(model, parameters, n_jobs=-1)\n",
    "grid.fit(clean.text, clean.labelmax)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run with unlabelled data\n",
    "\n",
    "I prefer to enrich the json with the predicted label instead of create a separate file with the labels only. In my experience, it's easier to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def read_json(path):\n",
    "    with path.open() as file:\n",
    "        return json.load(file)\n",
    "    \n",
    "def save_json(path, data):\n",
    "    with path.open('w') as file:\n",
    "        json.dump(data, file)\n",
    "\n",
    "data = pd.read_pickle('data/labelled_dataset.pickle')\n",
    "\n",
    "model = pipeline_with(LinearSVC(max_iter=5))\n",
    "model.fit(data.text, data.labelmax)\n",
    "\n",
    "Path('./data/labelled-dataset').mkdir(exist_ok=True)\n",
    "path = Path('./data/unlabelled-dataset').glob('*.json')\n",
    "for input_file in path:\n",
    "    data = read_json(input_file)\n",
    "    if len(data) == 0: continue\n",
    "        \n",
    "    features = [doc['text'] for doc in data]\n",
    "    predicted = model.predict(features)\n",
    "    \n",
    "    for doc, target in zip(data, predicted):\n",
    "        doc['predicted'] = target\n",
    "    \n",
    "    output_file = Path(file.parents[1]).joinpath('labelled-dataset', file.name)\n",
    "    save_json(output_file, data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience-challenge-W-kZqy1W",
   "language": "python",
   "name": "datascience-challenge-w-kzqy1w"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
