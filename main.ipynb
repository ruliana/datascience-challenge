{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing\n",
    "\n",
    "Fist run:\n",
    "\n",
    "    pipenv install\n",
    "    pipenv shell\n",
    "    python -m ipykernel install --user --name=<env-name>\n",
    "    jupyter notebook\n",
    "\n",
    "Once the kernel is installed:\n",
    "\n",
    "   pipenv run jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_predict, GridSearchCV\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ronie/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Easier to compare results\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from langdetect import detect as langdetect\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and check the format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labelmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pros - The people who work here are brilliant ...</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pros Start-up vibes Fast growing company Tech-...</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pros The team is great, I love the ambition of...</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pros The company is constantly growing, and at...</td>\n",
       "      <td>adaptability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pros Cool office. Friendly people. Good atmosp...</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       labelmax\n",
       "0  Pros - The people who work here are brilliant ...       customer\n",
       "1  Pros Start-up vibes Fast growing company Tech-...       customer\n",
       "2  Pros The team is great, I love the ambition of...  collaboration\n",
       "3  Pros The company is constantly growing, and at...   adaptability\n",
       "4  Pros Cool office. Friendly people. Good atmosp...  collaboration"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_pickle('data/labelled_dataset.pickle')\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Pros - The people who work here are brilliant (intelligent, hard-working etc.) - Exciting career opportunities, plenty of room to grow! - Great company culture, social events etc. - Management really value everyone's opinion and are open to ideas - Ambitious company, always working to grow and improve - I feel like my work is really valued, and outstanding performance is always recognised by management Cons - Salary isn't great compared to other grad jobs, hopefully this will improve as the company grows - Occasionally have to work weekends, would much rather there was a separate weekend team - Communication could be better about changes in the company, future plans etc. Advice to Management - Keep listening to your employees - Don't become cold and corporate. Airsorted needs to keep the company spirit, even when it is a big global company.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are unbalanced... hmmm.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer         26981\n",
       "collaboration    21067\n",
       "result           18948\n",
       "adaptability     17204\n",
       "detail            4030\n",
       "integrity         2815\n",
       "null               535\n",
       "Name: labelmax, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.labelmax.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labelmax</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pros - The people who work here are brilliant ...</td>\n",
       "      <td>customer</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pros Start-up vibes Fast growing company Tech-...</td>\n",
       "      <td>customer</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pros The team is great, I love the ambition of...</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pros The company is constantly growing, and at...</td>\n",
       "      <td>adaptability</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pros Cool office. Friendly people. Good atmosp...</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       labelmax lang\n",
       "0  Pros - The people who work here are brilliant ...       customer   en\n",
       "1  Pros Start-up vibes Fast growing company Tech-...       customer   en\n",
       "2  Pros The team is great, I love the ambition of...  collaboration   en\n",
       "3  Pros The company is constantly growing, and at...   adaptability   en\n",
       "4  Pros Cool office. Friendly people. Good atmosp...  collaboration   en"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw['lang'] = raw.text.apply(langdetect) # Language Detection\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uncomment during development\n",
    "#raw.to_pickle('data/labelled_dataset_lang.pickle')\n",
    "raw = pd.read_pickle('data/labelled_dataset_lang.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    88711\n",
       "de     2090\n",
       "fr      502\n",
       "nl      251\n",
       "es       17\n",
       "pt        4\n",
       "it        2\n",
       "af        1\n",
       "no        1\n",
       "cy        1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(raw.lang.value_counts())\n",
    "clean = raw[(raw.labelmax != 'null') & (raw.lang == 'en')] # Keep only english comments with classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import EnglishStemmer\n",
    "\n",
    "stemmer = EnglishStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def process_words(doc):\n",
    "    words = [stemmer.stem(w) for w in analyzer(doc)]\n",
    "    return ['NUMBER' if word.isdigit() else word for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29654"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(clean.text, clean.labelmax, test_size=0.1, stratify=clean.labelmax)\n",
    "\n",
    "word_counter = TfidfVectorizer(stop_words='english',\n",
    "                               analyzer=process_words,\n",
    "                               ngram_range=(1, 3))\n",
    "features = word_counter.fit_transform(features_train)\n",
    "feature_names = word_counter.get_feature_names()\n",
    "display(len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LinearSVC(C=0.25, class_weight={'detail': 3, 'integrity': 3}, dual=False,\n",
       "     fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
       "     max_iter=1000, multi_class='ovr', penalty='l1', random_state=None,\n",
       "     tol=0.0001, verbose=0),\n",
       "  n_features_to_select=5000, step=0.25, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(class_weight={'detail': 3, 'integrity': 3}, penalty='l1', dual=False, C=0.25)\n",
    "rfe = RFE(model, 5000, step=0.25)\n",
    "rfe.fit(features, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(np.array(feature_names)[rfe.support_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Train Accuracy: 0.909261765148098'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Test Accuracy: 0.8800315706393055'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LinearSVC(class_weight={'detail': 3, 'integrity': 3}, penalty='l1', dual=False, C=0.25)\n",
    "model.fit(rfe.transform(features), target_train)\n",
    "\n",
    "predicted_train = model.predict(rfe.transform(features))\n",
    "predicted_test = model.predict(rfe.transform(word_counter.transform(features_test)))\n",
    "\n",
    "labels = sorted(set(target_train))\n",
    "cm_train = confusion_matrix(target_train, predicted_train, labels)\n",
    "cm_test = confusion_matrix(target_test, predicted_test, labels)\n",
    "\n",
    "display('Train Accuracy: {}'.format(accuracy_score(target_train, predicted_train)))\n",
    "display('Test Accuracy: {}'.format(accuracy_score(target_test, predicted_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, charts = plt.subplots(2, 2, figsize=(15, 6), sharex=True, sharey=True)\n",
    "\n",
    "charts[0, 0].set_title('Precision Train')\n",
    "sns.heatmap(cm_train / cm_train.sum(axis=0),\n",
    "            ax=charts[0, 0],\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            xticklabels=labels,\n",
    "            yticklabels=labels,\n",
    "            vmin=0, vmax=1)\n",
    "\n",
    "charts[0, 1].set_title('Recall Train')\n",
    "sns.heatmap(cm_train / cm_train.sum(axis=1),\n",
    "            ax=charts[0, 1],\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            xticklabels=labels,\n",
    "            yticklabels=labels,\n",
    "            vmin=0, vmax=1)\n",
    "\n",
    "charts[1, 0].set_title('Precision Test')\n",
    "sns.heatmap(cm_test / cm_test.sum(axis=0),\n",
    "            ax=charts[1, 0],\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            xticklabels=labels,\n",
    "            yticklabels=labels,\n",
    "            vmin=0, vmax=1)\n",
    "\n",
    "charts[1, 1].set_title('Recall Test')\n",
    "sns.heatmap(cm_test / cm_test.sum(axis=1),\n",
    "            ax=charts[1, 1],\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            xticklabels=labels,\n",
    "            yticklabels=labels,\n",
    "            vmin=0, vmax=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run with unlabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def read_json(path):\n",
    "    with path.open() as file:\n",
    "        return json.load(file)\n",
    "    \n",
    "def save_json(path, data):\n",
    "    with path.open('w') as file:\n",
    "        json.dump(data, file)\n",
    "\n",
    "data = pd.read_pickle('data/labelled_dataset.pickle')\n",
    "\n",
    "model = pipeline_with(LinearSVC())\n",
    "model.fit(data.text, data.labelmax)\n",
    "\n",
    "Path('./data/labelled-dataset').mkdir(exist_ok=True)\n",
    "path = Path('./data/unlabelled-dataset').glob('*.json')\n",
    "for input_file in path:\n",
    "    data = read_json(input_file)\n",
    "    if len(data) == 0: continue\n",
    "        \n",
    "    features = [doc['text'] for doc in data]\n",
    "    predicted = model.predict(features)\n",
    "    \n",
    "    for doc, target in zip(data, predicted):\n",
    "        doc['predicted'] = target\n",
    "    \n",
    "    output_file = Path(file.parents[1]).joinpath('labelled-dataset', file.name)\n",
    "    save_json(output_file, data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience-challenge-W-kZqy1W",
   "language": "python",
   "name": "datascience-challenge-w-kzqy1w"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
