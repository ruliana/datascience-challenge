{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Challenge\n",
    "\n",
    "(refer to README for the challenge description)\n",
    "\n",
    "My first approach was to stick to the basics: TF-IDF + Naive Bayes. The results were no good, so I tried several flavors of SVM.\n",
    "\n",
    "Why?\n",
    "\n",
    "Naive Bayes is simple, fast and had some great results in the past for text classification. I try it first to have a baseline.\n",
    "\n",
    "SVM seems to be one of the best in the present days, unless we go to Neural Networks, I guess, so it was my next step. The classification accuracy increased a lot.\n",
    "\n",
    "I didn't reach accuracy over 90% as the pre-requisites, probably my data preparation is poor. I tried stemming, but the results didn't improved much. Maybe Latent Semantic Analysis to identify synonyms, but it seem too much right now.\n",
    "\n",
    "As you asked for >90% accuracy in 2-4 hours, my feeling is that I'm missing something really obvious here. But...\n",
    "\n",
    "Anyway... my next steps would be:\n",
    "\n",
    "1. Talk to someone more experienced on that (in a real situation, of course).\n",
    "2. Search a little more for another algorithm.\n",
    "3. Experimenting with feature engineering, the algorithms don't make miracles, but playing with the features usually leads to big improvements. That's were I'm probably missing something, like separate Pros and Cons.\n",
    "4. Spend a little more time doing Grid Search. It's slow, but requires only computer time, and also it can improve a lot some models.\n",
    "5. Precision and Recall. I wouldn't finish this without calculate them. IMHO, they provide a good picture of the model performance. Accuracy can be misleading,\n",
    "\n",
    "Also, I would create separate models for each language. The stemming in languages that have more verb flexion (latin languages mostly) can make a bigger difference.\n",
    "\n",
    "Finally, I made a big mistake here, I tried to use the whole data set for all algorithms. It's fast for the MultinomialNB and SGDClassifier, but it was really slow with the other algorithms I tried (SVC, NuSVC, XGBoost). That made me spend a lot of time just waiting instead of play more with the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing\n",
    "\n",
    "Fist run:\n",
    "\n",
    "    pipenv install\n",
    "    pipenv shell\n",
    "    python -m ipykernel install --user --name=<env-name>\n",
    "    jupyter notebook\n",
    "\n",
    "Once the kernel is installed:\n",
    "\n",
    "   pipenv run jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ronie/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Easier to compare results\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and check the format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labelmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pros - The people who work here are brilliant ...</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pros Start-up vibes Fast growing company Tech-...</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pros The team is great, I love the ambition of...</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pros The company is constantly growing, and at...</td>\n",
       "      <td>adaptability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pros Cool office. Friendly people. Good atmosp...</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       labelmax\n",
       "0  Pros - The people who work here are brilliant ...       customer\n",
       "1  Pros Start-up vibes Fast growing company Tech-...       customer\n",
       "2  Pros The team is great, I love the ambition of...  collaboration\n",
       "3  Pros The company is constantly growing, and at...   adaptability\n",
       "4  Pros Cool office. Friendly people. Good atmosp...  collaboration"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_pickle('data/labelled_dataset.pickle')\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Pros - The people who work here are brilliant (intelligent, hard-working etc.) - Exciting career opportunities, plenty of room to grow! - Great company culture, social events etc. - Management really value everyone's opinion and are open to ideas - Ambitious company, always working to grow and improve - I feel like my work is really valued, and outstanding performance is always recognised by management Cons - Salary isn't great compared to other grad jobs, hopefully this will improve as the company grows - Occasionally have to work weekends, would much rather there was a separate weekend team - Communication could be better about changes in the company, future plans etc. Advice to Management - Keep listening to your employees - Don't become cold and corporate. Airsorted needs to keep the company spirit, even when it is a big global company.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer         26981\n",
       "collaboration    21067\n",
       "result           18948\n",
       "adaptability     17204\n",
       "detail            4030\n",
       "integrity         2815\n",
       "null               535\n",
       "Name: labelmax, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.labelmax.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = raw[raw.labelmax != 'null'] # No classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I tried stemming too soon before.\n",
    "# As some of the last steps, it increase the model accuracy by 5 to 6 percentual points, from ~0.76 to ~0.82.\n",
    "# That's the difference between 1/4 to 1/5, not bad. However, the model now spend too much time training and\n",
    "# the experimentation slowed down a lot. Maybe I should reduce the dataset in this phase.\n",
    "\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "\n",
    "stemmer = EnglishStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers\n",
    "\n",
    "This little functions help to test with different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextFeatures(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, texts):\n",
    "        rslt = []\n",
    "        for text in texts:\n",
    "            pros, cons = re.match(r'Pros(.+)Cons(.+)', text).groups()\n",
    "            rslt.append({'pros_length': len(pros),\n",
    "                         'pros_topics': pros.count('-'),\n",
    "                         'cons_length': len(cons),\n",
    "                         'cons_topics': cons.count('-')})\n",
    "        return rslt\n",
    "    \n",
    "def pipeline_with(classifier):\n",
    "    \"Base pipeline for text classification using bag of words\"\n",
    "    word_counter = CountVectorizer(stop_words='english',\n",
    "                                   analyzer=stemmed_words,\n",
    "                                   max_df=0.98, # Remove domain specific words like \"Pros\" and \"Cons\"\n",
    "                                   min_df=3)  # Remove words rarely seen\n",
    "\n",
    "    return Pipeline([('union', FeatureUnion([('bow',\n",
    "                                              Pipeline([('frequency', word_counter),\n",
    "                                                        ('tfidf', TfidfTransformer())])),\n",
    "                                             ('text',\n",
    "                                              Pipeline([('features', TextFeatures()),\n",
    "                                                        ('vectorizer', DictVectorizer(sparse=False)),\n",
    "                                                        ('scaler', MinMaxScaler())]))])),\n",
    "                     ('model', classifier)])\n",
    "\n",
    "def fast_accuracy_for(model, features, target):\n",
    "    \"Simple train test split, so we spend less time testing\"\n",
    "    features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2)\n",
    "    pipeline = pipeline_with(model)\n",
    "    pipeline.fit(features_train, target_train)\n",
    "    target_predicted = pipeline.predict(features_test)\n",
    "    return accuracy_score(target_test, target_predicted)\n",
    "    \n",
    "\n",
    "def scores_for(model, features, target):\n",
    "    \"Use cross validation for more reliable results, replace 'fast_accuracy_for' with this after some tests.\"\n",
    "    scores = cross_validate(pipeline_with(model), features, target,\n",
    "                              scoring=['accuracy', 'recall_macro', 'precision_macro'],\n",
    "                              return_train_score=False,\n",
    "                              cv=5, n_jobs=3)\n",
    "    return {k: np.mean(v) for k, v in scores.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Naive Bayes is my first try to classify texts. Sometimes it is good enough and it's fast, I use it as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([151.58923173, 146.28640103, 113.25049996]), 'score_time': array([139.91203356, 209.29278708, 213.56147528]), 'test_accuracy': array([0.51345919, 0.49680374, 0.49855006]), 'test_recall_macro': array([0.35050865, 0.33543207, 0.33260133]), 'test_precision_macro': array([0.37630908, 0.45693172, 0.4397979 ])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "print(scores_for(MultinomialNB(), clean.text, clean.labelmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "SVM does a great job with text classification. As expected, the performance here makes a great jump from Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7942775550551925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "print(accuracy_for(SGDClassifier(max_iter=1000), clean.text, clean.labelmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': 155.57943754196168, 'score_time': 101.06812071800232, 'test_accuracy': 0.8296331983860641, 'test_recall_macro': 0.7475973719554054, 'test_precision_macro': 0.8177883532026818}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "print(scores_for(LinearSVC(), clean.text, clean.labelmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I should play a little more with the features, but before that, let's try to extract the maximum possible with this algorithm. Ensembles are kinda cheap to implement and test and sometimes it can improves the model with just one or two lines of codes (and a lot of processing).\n",
    "\n",
    "In this case, a very little sample gives the same accuracy. Which probably means we don't need so much samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-1ae2dc936da5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaggingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaggingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabelmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-137-faefc5e42e24>\u001b[0m in \u001b[0;36mscores_for\u001b[0;34m(model, features, target)\u001b[0m\n\u001b[1;32m     44\u001b[0m                               \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recall_macro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'precision_macro'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                               \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                               cv=3, n_jobs=3)\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ronie/.local/share/virtualenvs/datascience-challenge-W-kZqy1W/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ronie/.local/share/virtualenvs/datascience-challenge-W-kZqy1W/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ronie/.local/share/virtualenvs/datascience-challenge-W-kZqy1W/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ronie/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ronie/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ronie/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ronie/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "model = BaggingClassifier(LinearSVC(), max_samples=0.1, n_estimators=15)\n",
    "print(scores_for(model, clean.text, clean.labelmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'model__max_samples': [0.2, 0.4, 0.6, 0.8],\n",
    "              'model__n_estimators': [10, 50, 100, 500],}\n",
    "\n",
    "model = pipeline_with(BaggingClassifier(LinearSVC()))\n",
    "grid = GridSearchCV(model, parameters, n_jobs=-1)\n",
    "grid.fit(clean.text, clean.labelmax)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the probabilities are going for the LinearSVC.\n",
    "\n",
    "(As it has no \"predict_proba\" method, we need to put it inside a CalibratedClassifierCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.29012638e-01, 6.53272858e-02, 7.02847748e-01, 1.70583291e-05,\n",
       "        1.47171430e-05, 2.78055290e-03],\n",
       "       [2.32969359e-01, 2.28206531e-01, 5.38774786e-01, 4.40663724e-06,\n",
       "        2.26231892e-06, 4.26544256e-05],\n",
       "       [3.37507621e-02, 9.62128793e-01, 5.50265983e-04, 1.44398853e-03,\n",
       "        1.39634793e-03, 7.29842829e-04],\n",
       "       ...,\n",
       "       [1.56789131e-03, 9.92471497e-01, 1.08110477e-03, 1.62034729e-03,\n",
       "        2.46655598e-05, 3.23449382e-03],\n",
       "       [1.78588282e-03, 5.28711306e-01, 9.33329978e-02, 3.75461398e-01,\n",
       "        1.01236476e-05, 6.98291614e-04],\n",
       "       [1.21908089e-01, 3.34450535e-01, 7.01324078e-04, 3.57798761e-04,\n",
       "        5.39491511e-01, 3.09074221e-03]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "model = CalibratedClassifierCV(LinearSVC())\n",
    "prediction = cross_val_predict(pipeline_with(model), clean.text, clean.labelmax,\n",
    "                               method='predict_proba',\n",
    "                               cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adaptability</th>\n",
       "      <th>collaboration</th>\n",
       "      <th>customer</th>\n",
       "      <th>detail</th>\n",
       "      <th>integrity</th>\n",
       "      <th>result</th>\n",
       "      <th>classified</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.22901</td>\n",
       "      <td>0.06533</td>\n",
       "      <td>0.70285</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00278</td>\n",
       "      <td>customer</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.23297</td>\n",
       "      <td>0.22821</td>\n",
       "      <td>0.53877</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>customer</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03375</td>\n",
       "      <td>0.96213</td>\n",
       "      <td>0.00055</td>\n",
       "      <td>0.00144</td>\n",
       "      <td>0.00140</td>\n",
       "      <td>0.00073</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.96971</td>\n",
       "      <td>0.01834</td>\n",
       "      <td>0.00763</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00427</td>\n",
       "      <td>adaptability</td>\n",
       "      <td>adaptability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.45953</td>\n",
       "      <td>0.53793</td>\n",
       "      <td>0.00241</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00624</td>\n",
       "      <td>0.97068</td>\n",
       "      <td>0.00116</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.02186</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00859</td>\n",
       "      <td>0.88693</td>\n",
       "      <td>0.07386</td>\n",
       "      <td>0.03008</td>\n",
       "      <td>0.00042</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.09093</td>\n",
       "      <td>0.34031</td>\n",
       "      <td>0.56535</td>\n",
       "      <td>0.00170</td>\n",
       "      <td>0.00070</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>customer</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.34056</td>\n",
       "      <td>0.08486</td>\n",
       "      <td>0.51683</td>\n",
       "      <td>0.02330</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>0.03381</td>\n",
       "      <td>customer</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00050</td>\n",
       "      <td>0.87131</td>\n",
       "      <td>0.12193</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.00171</td>\n",
       "      <td>0.00430</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.20268</td>\n",
       "      <td>0.43253</td>\n",
       "      <td>0.07517</td>\n",
       "      <td>0.27988</td>\n",
       "      <td>0.00144</td>\n",
       "      <td>0.00830</td>\n",
       "      <td>detail</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.41246</td>\n",
       "      <td>0.45929</td>\n",
       "      <td>0.00846</td>\n",
       "      <td>0.00217</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.11756</td>\n",
       "      <td>adaptability</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.01328</td>\n",
       "      <td>0.12092</td>\n",
       "      <td>0.81938</td>\n",
       "      <td>0.04398</td>\n",
       "      <td>0.00198</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>customer</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.76189</td>\n",
       "      <td>0.14478</td>\n",
       "      <td>0.08426</td>\n",
       "      <td>0.00064</td>\n",
       "      <td>0.00598</td>\n",
       "      <td>0.00245</td>\n",
       "      <td>adaptability</td>\n",
       "      <td>adaptability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.87511</td>\n",
       "      <td>0.07019</td>\n",
       "      <td>0.02615</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.02845</td>\n",
       "      <td>adaptability</td>\n",
       "      <td>adaptability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.24992</td>\n",
       "      <td>0.74493</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>0.00476</td>\n",
       "      <td>customer</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.00027</td>\n",
       "      <td>0.53735</td>\n",
       "      <td>0.46023</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>0.00175</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.00607</td>\n",
       "      <td>0.03177</td>\n",
       "      <td>0.61499</td>\n",
       "      <td>0.04781</td>\n",
       "      <td>0.10412</td>\n",
       "      <td>0.19524</td>\n",
       "      <td>customer</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.00030</td>\n",
       "      <td>0.93954</td>\n",
       "      <td>0.05223</td>\n",
       "      <td>0.00753</td>\n",
       "      <td>0.00037</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.00396</td>\n",
       "      <td>0.43963</td>\n",
       "      <td>0.31036</td>\n",
       "      <td>0.00096</td>\n",
       "      <td>0.00204</td>\n",
       "      <td>0.24305</td>\n",
       "      <td>customer</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.07468</td>\n",
       "      <td>0.92056</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00474</td>\n",
       "      <td>customer</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.51204</td>\n",
       "      <td>0.45587</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.03202</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.06869</td>\n",
       "      <td>0.00169</td>\n",
       "      <td>0.86874</td>\n",
       "      <td>0.00093</td>\n",
       "      <td>0.00131</td>\n",
       "      <td>0.05865</td>\n",
       "      <td>customer</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.11819</td>\n",
       "      <td>0.63730</td>\n",
       "      <td>0.24225</td>\n",
       "      <td>0.00059</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>0.00128</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.00069</td>\n",
       "      <td>0.31437</td>\n",
       "      <td>0.68357</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00118</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>customer</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.06898</td>\n",
       "      <td>0.03037</td>\n",
       "      <td>0.89602</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.00051</td>\n",
       "      <td>0.00406</td>\n",
       "      <td>customer</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.04319</td>\n",
       "      <td>0.92734</td>\n",
       "      <td>0.00443</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.02465</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.64814</td>\n",
       "      <td>0.00461</td>\n",
       "      <td>0.34614</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00107</td>\n",
       "      <td>adaptability</td>\n",
       "      <td>adaptability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.00748</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.05328</td>\n",
       "      <td>0.29339</td>\n",
       "      <td>0.07496</td>\n",
       "      <td>0.57053</td>\n",
       "      <td>detail</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.00218</td>\n",
       "      <td>0.28021</td>\n",
       "      <td>0.24360</td>\n",
       "      <td>0.33876</td>\n",
       "      <td>0.00061</td>\n",
       "      <td>0.13464</td>\n",
       "      <td>detail</td>\n",
       "      <td>detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91015</th>\n",
       "      <td>0.04789</td>\n",
       "      <td>0.13118</td>\n",
       "      <td>0.05561</td>\n",
       "      <td>0.68013</td>\n",
       "      <td>0.01138</td>\n",
       "      <td>0.07380</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91016</th>\n",
       "      <td>0.49319</td>\n",
       "      <td>0.50562</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00022</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.00071</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91017</th>\n",
       "      <td>0.08778</td>\n",
       "      <td>0.00748</td>\n",
       "      <td>0.00017</td>\n",
       "      <td>0.00084</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.90368</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91018</th>\n",
       "      <td>0.00526</td>\n",
       "      <td>0.01071</td>\n",
       "      <td>0.00223</td>\n",
       "      <td>0.00523</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.97658</td>\n",
       "      <td>adaptability</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91019</th>\n",
       "      <td>0.00051</td>\n",
       "      <td>0.51273</td>\n",
       "      <td>0.21476</td>\n",
       "      <td>0.05286</td>\n",
       "      <td>0.21203</td>\n",
       "      <td>0.00712</td>\n",
       "      <td>detail</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91020</th>\n",
       "      <td>0.03845</td>\n",
       "      <td>0.00029</td>\n",
       "      <td>0.31232</td>\n",
       "      <td>0.00070</td>\n",
       "      <td>0.18584</td>\n",
       "      <td>0.46240</td>\n",
       "      <td>adaptability</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91021</th>\n",
       "      <td>0.00186</td>\n",
       "      <td>0.81184</td>\n",
       "      <td>0.07395</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.01499</td>\n",
       "      <td>0.09734</td>\n",
       "      <td>customer</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91022</th>\n",
       "      <td>0.06342</td>\n",
       "      <td>0.66489</td>\n",
       "      <td>0.24141</td>\n",
       "      <td>0.00079</td>\n",
       "      <td>0.02928</td>\n",
       "      <td>0.00021</td>\n",
       "      <td>adaptability</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91023</th>\n",
       "      <td>0.00019</td>\n",
       "      <td>0.62279</td>\n",
       "      <td>0.37452</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00167</td>\n",
       "      <td>0.00074</td>\n",
       "      <td>customer</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91024</th>\n",
       "      <td>0.63593</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.06296</td>\n",
       "      <td>0.00982</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>0.29079</td>\n",
       "      <td>customer</td>\n",
       "      <td>adaptability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91025</th>\n",
       "      <td>0.00259</td>\n",
       "      <td>0.95066</td>\n",
       "      <td>0.01126</td>\n",
       "      <td>0.00109</td>\n",
       "      <td>0.01737</td>\n",
       "      <td>0.01702</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91026</th>\n",
       "      <td>0.28574</td>\n",
       "      <td>0.49817</td>\n",
       "      <td>0.21254</td>\n",
       "      <td>0.00037</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>result</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91027</th>\n",
       "      <td>0.00038</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.38974</td>\n",
       "      <td>0.00056</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.60928</td>\n",
       "      <td>customer</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91028</th>\n",
       "      <td>0.98653</td>\n",
       "      <td>0.00149</td>\n",
       "      <td>0.00855</td>\n",
       "      <td>0.00141</td>\n",
       "      <td>0.00054</td>\n",
       "      <td>0.00148</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>adaptability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91029</th>\n",
       "      <td>0.00697</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.07927</td>\n",
       "      <td>0.00249</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.91124</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91030</th>\n",
       "      <td>0.52952</td>\n",
       "      <td>0.32369</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00019</td>\n",
       "      <td>0.00098</td>\n",
       "      <td>0.14555</td>\n",
       "      <td>result</td>\n",
       "      <td>adaptability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91031</th>\n",
       "      <td>0.88026</td>\n",
       "      <td>0.00775</td>\n",
       "      <td>0.05964</td>\n",
       "      <td>0.00198</td>\n",
       "      <td>0.00028</td>\n",
       "      <td>0.05009</td>\n",
       "      <td>adaptability</td>\n",
       "      <td>adaptability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91032</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.26312</td>\n",
       "      <td>0.57329</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.16348</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91033</th>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.30313</td>\n",
       "      <td>0.14484</td>\n",
       "      <td>0.00606</td>\n",
       "      <td>0.54589</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91034</th>\n",
       "      <td>0.41351</td>\n",
       "      <td>0.48301</td>\n",
       "      <td>0.06125</td>\n",
       "      <td>0.00533</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.03688</td>\n",
       "      <td>adaptability</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91035</th>\n",
       "      <td>0.00061</td>\n",
       "      <td>0.66935</td>\n",
       "      <td>0.06090</td>\n",
       "      <td>0.07435</td>\n",
       "      <td>0.03382</td>\n",
       "      <td>0.16097</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91036</th>\n",
       "      <td>0.00575</td>\n",
       "      <td>0.00555</td>\n",
       "      <td>0.91405</td>\n",
       "      <td>0.00272</td>\n",
       "      <td>0.00271</td>\n",
       "      <td>0.06922</td>\n",
       "      <td>result</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91037</th>\n",
       "      <td>0.00218</td>\n",
       "      <td>0.04441</td>\n",
       "      <td>0.48987</td>\n",
       "      <td>0.01162</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.45192</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91038</th>\n",
       "      <td>0.01519</td>\n",
       "      <td>0.01871</td>\n",
       "      <td>0.35516</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.60040</td>\n",
       "      <td>adaptability</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91039</th>\n",
       "      <td>0.21782</td>\n",
       "      <td>0.00034</td>\n",
       "      <td>0.77491</td>\n",
       "      <td>0.00038</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00652</td>\n",
       "      <td>customer</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91040</th>\n",
       "      <td>0.00111</td>\n",
       "      <td>0.07887</td>\n",
       "      <td>0.22259</td>\n",
       "      <td>0.00032</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>0.69670</td>\n",
       "      <td>customer</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91041</th>\n",
       "      <td>0.00070</td>\n",
       "      <td>0.11032</td>\n",
       "      <td>0.87448</td>\n",
       "      <td>0.00306</td>\n",
       "      <td>0.00042</td>\n",
       "      <td>0.01102</td>\n",
       "      <td>customer</td>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91042</th>\n",
       "      <td>0.00157</td>\n",
       "      <td>0.99247</td>\n",
       "      <td>0.00108</td>\n",
       "      <td>0.00162</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00323</td>\n",
       "      <td>integrity</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91043</th>\n",
       "      <td>0.00179</td>\n",
       "      <td>0.52871</td>\n",
       "      <td>0.09333</td>\n",
       "      <td>0.37546</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00070</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>collaboration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91044</th>\n",
       "      <td>0.12191</td>\n",
       "      <td>0.33445</td>\n",
       "      <td>0.00070</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.53949</td>\n",
       "      <td>0.00309</td>\n",
       "      <td>customer</td>\n",
       "      <td>integrity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91045 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       adaptability  collaboration  customer  detail  integrity  result  \\\n",
       "0           0.22901        0.06533   0.70285 0.00002    0.00001 0.00278   \n",
       "1           0.23297        0.22821   0.53877 0.00000    0.00000 0.00004   \n",
       "2           0.03375        0.96213   0.00055 0.00144    0.00140 0.00073   \n",
       "3           0.96971        0.01834   0.00763 0.00001    0.00004 0.00427   \n",
       "4           0.45953        0.53793   0.00241 0.00002    0.00004 0.00007   \n",
       "5           0.00624        0.97068   0.00116 0.00001    0.00005 0.02186   \n",
       "6           0.00859        0.88693   0.07386 0.03008    0.00042 0.00012   \n",
       "7           0.09093        0.34031   0.56535 0.00170    0.00070 0.00100   \n",
       "8           0.34056        0.08486   0.51683 0.02330    0.00065 0.03381   \n",
       "9           0.00050        0.87131   0.12193 0.00025    0.00171 0.00430   \n",
       "10          0.20268        0.43253   0.07517 0.27988    0.00144 0.00830   \n",
       "11          0.41246        0.45929   0.00846 0.00217    0.00006 0.11756   \n",
       "12          0.01328        0.12092   0.81938 0.04398    0.00198 0.00047   \n",
       "13          0.76189        0.14478   0.08426 0.00064    0.00598 0.00245   \n",
       "14          0.87511        0.07019   0.02615 0.00002    0.00006 0.02845   \n",
       "15          0.00000        0.24992   0.74493 0.00000    0.00039 0.00476   \n",
       "16          0.00027        0.53735   0.46023 0.00001    0.00039 0.00175   \n",
       "17          0.00607        0.03177   0.61499 0.04781    0.10412 0.19524   \n",
       "18          0.00030        0.93954   0.05223 0.00753    0.00037 0.00003   \n",
       "19          0.00396        0.43963   0.31036 0.00096    0.00204 0.24305   \n",
       "20          0.00001        0.07468   0.92056 0.00000    0.00000 0.00474   \n",
       "21          0.00006        0.51204   0.45587 0.00000    0.00000 0.03202   \n",
       "22          0.06869        0.00169   0.86874 0.00093    0.00131 0.05865   \n",
       "23          0.11819        0.63730   0.24225 0.00059    0.00039 0.00128   \n",
       "24          0.00069        0.31437   0.68357 0.00008    0.00118 0.00011   \n",
       "25          0.06898        0.03037   0.89602 0.00005    0.00051 0.00406   \n",
       "26          0.04319        0.92734   0.00443 0.00006    0.00033 0.02465   \n",
       "27          0.64814        0.00461   0.34614 0.00000    0.00004 0.00107   \n",
       "28          0.00748        0.00036   0.05328 0.29339    0.07496 0.57053   \n",
       "29          0.00218        0.28021   0.24360 0.33876    0.00061 0.13464   \n",
       "...             ...            ...       ...     ...        ...     ...   \n",
       "91015       0.04789        0.13118   0.05561 0.68013    0.01138 0.07380   \n",
       "91016       0.49319        0.50562   0.00001 0.00022    0.00025 0.00071   \n",
       "91017       0.08778        0.00748   0.00017 0.00084    0.00004 0.90368   \n",
       "91018       0.00526        0.01071   0.00223 0.00523    0.00000 0.97658   \n",
       "91019       0.00051        0.51273   0.21476 0.05286    0.21203 0.00712   \n",
       "91020       0.03845        0.00029   0.31232 0.00070    0.18584 0.46240   \n",
       "91021       0.00186        0.81184   0.07395 0.00001    0.01499 0.09734   \n",
       "91022       0.06342        0.66489   0.24141 0.00079    0.02928 0.00021   \n",
       "91023       0.00019        0.62279   0.37452 0.00009    0.00167 0.00074   \n",
       "91024       0.63593        0.00011   0.06296 0.00982    0.00039 0.29079   \n",
       "91025       0.00259        0.95066   0.01126 0.00109    0.01737 0.01702   \n",
       "91026       0.28574        0.49817   0.21254 0.00037    0.00295 0.00024   \n",
       "91027       0.00038        0.00003   0.38974 0.00056    0.00001 0.60928   \n",
       "91028       0.98653        0.00149   0.00855 0.00141    0.00054 0.00148   \n",
       "91029       0.00697        0.00003   0.07927 0.00249    0.00000 0.91124   \n",
       "91030       0.52952        0.32369   0.00007 0.00019    0.00098 0.14555   \n",
       "91031       0.88026        0.00775   0.05964 0.00198    0.00028 0.05009   \n",
       "91032       0.00001        0.26312   0.57329 0.00000    0.16348 0.00010   \n",
       "91033       0.00002        0.00005   0.30313 0.14484    0.00606 0.54589   \n",
       "91034       0.41351        0.48301   0.06125 0.00533    0.00002 0.03688   \n",
       "91035       0.00061        0.66935   0.06090 0.07435    0.03382 0.16097   \n",
       "91036       0.00575        0.00555   0.91405 0.00272    0.00271 0.06922   \n",
       "91037       0.00218        0.04441   0.48987 0.01162    0.00001 0.45192   \n",
       "91038       0.01519        0.01871   0.35516 0.01050    0.00003 0.60040   \n",
       "91039       0.21782        0.00034   0.77491 0.00038    0.00003 0.00652   \n",
       "91040       0.00111        0.07887   0.22259 0.00032    0.00040 0.69670   \n",
       "91041       0.00070        0.11032   0.87448 0.00306    0.00042 0.01102   \n",
       "91042       0.00157        0.99247   0.00108 0.00162    0.00002 0.00323   \n",
       "91043       0.00179        0.52871   0.09333 0.37546    0.00001 0.00070   \n",
       "91044       0.12191        0.33445   0.00070 0.00036    0.53949 0.00309   \n",
       "\n",
       "          classified      predicted  \n",
       "0           customer       customer  \n",
       "1           customer       customer  \n",
       "2      collaboration  collaboration  \n",
       "3       adaptability   adaptability  \n",
       "4      collaboration  collaboration  \n",
       "5      collaboration  collaboration  \n",
       "6      collaboration  collaboration  \n",
       "7           customer       customer  \n",
       "8           customer       customer  \n",
       "9      collaboration  collaboration  \n",
       "10            detail  collaboration  \n",
       "11      adaptability  collaboration  \n",
       "12          customer       customer  \n",
       "13      adaptability   adaptability  \n",
       "14      adaptability   adaptability  \n",
       "15          customer       customer  \n",
       "16     collaboration  collaboration  \n",
       "17          customer       customer  \n",
       "18     collaboration  collaboration  \n",
       "19          customer  collaboration  \n",
       "20          customer       customer  \n",
       "21     collaboration  collaboration  \n",
       "22          customer       customer  \n",
       "23     collaboration  collaboration  \n",
       "24          customer       customer  \n",
       "25          customer       customer  \n",
       "26     collaboration  collaboration  \n",
       "27      adaptability   adaptability  \n",
       "28            detail         result  \n",
       "29            detail         detail  \n",
       "...              ...            ...  \n",
       "91015  collaboration         detail  \n",
       "91016  collaboration  collaboration  \n",
       "91017  collaboration         result  \n",
       "91018   adaptability         result  \n",
       "91019         detail  collaboration  \n",
       "91020   adaptability         result  \n",
       "91021       customer  collaboration  \n",
       "91022   adaptability  collaboration  \n",
       "91023       customer  collaboration  \n",
       "91024       customer   adaptability  \n",
       "91025  collaboration  collaboration  \n",
       "91026         result  collaboration  \n",
       "91027       customer         result  \n",
       "91028  collaboration   adaptability  \n",
       "91029  collaboration         result  \n",
       "91030         result   adaptability  \n",
       "91031   adaptability   adaptability  \n",
       "91032  collaboration       customer  \n",
       "91033  collaboration         result  \n",
       "91034   adaptability  collaboration  \n",
       "91035  collaboration  collaboration  \n",
       "91036         result       customer  \n",
       "91037  collaboration       customer  \n",
       "91038   adaptability         result  \n",
       "91039       customer       customer  \n",
       "91040       customer         result  \n",
       "91041       customer       customer  \n",
       "91042      integrity  collaboration  \n",
       "91043  collaboration  collaboration  \n",
       "91044       customer      integrity  \n",
       "\n",
       "[91045 rows x 8 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This actually a curryied function, it's a bit verbose on\n",
    "# Python, but I prefer to use it instead of create full classes\n",
    "# that do just one thing.\n",
    "def select_col(columns):\n",
    "    def max_index(values):\n",
    "        index, _ = max(enumerate(values), key=lambda e: e[1])\n",
    "        return columns[index]\n",
    "    return max_index\n",
    "\n",
    "col_names = sorted(set(clean.labelmax))\n",
    "get_predicted = select_col(col_names)\n",
    "\n",
    "df = pd.DataFrame(prediction, columns=col_names)\n",
    "df['classified'] = clean.labelmax\n",
    "df['predicted'] = list(map(get_predicted, prediction))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "Never used it before, but it's a winner in Kaggle competitions, so let's try it for text classification.\n",
    "\n",
    "Results:\n",
    "\n",
    "- It's way slower than the others.\n",
    "- No good results in the first run (acc ~0.5). I probably need to prepare the data better for text classification.\n",
    "- I got some warnings from scipy, but it seems expected.\n",
    "\n",
    "It was a very naive approach, but fairly cheap to try (but I spent 30 min waiting for a response, bad move)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from xgboost import XGBClassifier\n",
    "#print(fast_accuracy_for(XGBClassifier()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve best options\n",
    "\n",
    "Naive Bayes and SVM are great. Let's try to improve their parameters (took a long time). Here I experiment just for one algorithm, but I would try with others.\n",
    "\n",
    "Kinda of unexpected, but the default parameter were the best ones. Good from one hand, but I got a little disappointed, as it took a long time just to say \"yeap, the default are really ok\".\n",
    "\n",
    "Note: this took a whole day running, as expected :p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8221099456312813\n",
      "{'frequency__max_df': 0.9, 'frequency__min_df': 2, 'frequency__ngram_range': (1, 1), 'model__C': 1, 'tfidf__sublinear_tf': False}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'frequency__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "              'frequency__max_df': [0.5, 0.7, 0.9],\n",
    "              'frequency__min_df': [1, 2],\n",
    "              'tfidf__sublinear_tf': [True, False],\n",
    "              'model__C': [10, 1, 0.1, 0.001]}\n",
    "\n",
    "model = pipeline_with(LinearSVC()) \n",
    "grid = GridSearchCV(model, parameters, n_jobs=-1)\n",
    "grid.fit(clean.text, clean.labelmax)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run with unlabelled data\n",
    "\n",
    "I prefer to enrich the json with the predicted label instead of create a separate file with the labels only. In my experience, it's easier to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def read_json(path):\n",
    "    with path.open() as file:\n",
    "        return json.load(file)\n",
    "    \n",
    "def save_json(path, data):\n",
    "    with path.open('w') as file:\n",
    "        json.dump(data, file)\n",
    "\n",
    "data = pd.read_pickle('data/labelled_dataset.pickle')\n",
    "\n",
    "model = pipeline_with(LinearSVC())\n",
    "model.fit(data.text, data.labelmax)\n",
    "\n",
    "Path('./data/labelled-dataset').mkdir(exist_ok=True)\n",
    "path = Path('./data/unlabelled-dataset').glob('*.json')\n",
    "for input_file in path:\n",
    "    data = read_json(input_file)\n",
    "    if len(data) == 0: continue\n",
    "        \n",
    "    features = [doc['text'] for doc in data]\n",
    "    predicted = model.predict(features)\n",
    "    \n",
    "    for doc, target in zip(data, predicted):\n",
    "        doc['predicted'] = target\n",
    "    \n",
    "    output_file = Path(file.parents[1]).joinpath('labelled-dataset', file.name)\n",
    "    save_json(output_file, data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience-challenge-W-kZqy1W",
   "language": "python",
   "name": "datascience-challenge-w-kzqy1w"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
